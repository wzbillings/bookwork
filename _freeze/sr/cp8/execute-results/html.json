{
  "hash": "ab905c2adf152ba27bedf946e446bed2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 8: Conditional Manatees\"\ndate: 2024-01-24\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rethinking)\nlibrary(dagitty)\nlibrary(ggplot2)\n```\n:::\n\n\n\nThis chapter is a brief introduction to the concept of conditional inference,\nfocusing on the specific concept of linear interaction in models.\n\n## Chapter notes\n\n* Bullet holes in bombers and propeller scars on manatees -- both are\n*conditional on survival*. This is the motivating example for the chapter.\n* An *interaction* is a statistical method for modeling interdependence\nbetween two features of a model.\n* Using an interaction term in a model is nearly always better than fitting\nstratified models.\n* In Bayesian models, it's better to use an index-coding approach and have\nparameters vary by the level of a categorical variable, rather than using\nan indicator-coding approach, which makes assigning priors difficult.\n* An *interaction* is also just a slope which is conditional on another\neffect -- the value of one variable modifies the effect of the other.\n* Linear interactions are symmetrical. If variable $x$ interacts with\nvariable $y$, then $y$ interacts with $x$. \"There is just no way to specify\na simple, linear interaction in which you can say the effect of some\nvariable $x$ depends on $z$, but the effect of $z$ does not depend upon $x$.\"\n* Continuous interactions are harder to think about as conditional slopes,\nbecause we would need an uncountably infinite number of categories. Instead,\nwe can think about interactions as nested linear models.\n\n$$\n\\begin{aligned}\n\\mu_i &= \\alpha + \\gamma_{W,i}W_i + \\beta_S S_i \\\\\n\\gamma_{W,i} &= \\beta_{W} + \\beta_{WS} S_i\n\\end{aligned}\n$$\n\n* We could include nested terms for both variables, but the resultant\nmodel has unidentifiable parameters -- in the final term below, only the\nsum $(\\beta_{WS} + \\beta_{SW})$ can be estimated.\n\n$$\n\\begin{aligned}\n\\mu_i &= \\alpha + \\gamma_{W,i}W_i + \\gamma_{S,i} S_i \\\\\n\\gamma_{W,i} &= \\beta_{W} + \\beta_{WS} S_i \\\\\n\\gamma_{S_i} &= \\beta_{S} + \\beta_{SW} W_i \\\\\n\\therefore \\mu_i &= \\alpha + \\left(\\beta_{W} + \\beta_{WS} S_i\\right)W_i + \\left(\\beta_{S} + \\beta_{SW} W_i\\right) S_i \\\\\n&= \\alpha + \\beta_W W_i + \\beta_S S_i + (\\beta_{WS} + \\beta_{SW}) W_iS_i\n\\end{aligned}\n$$\n\n* The best way to understand interactions is to plot the predictions at multiple\nlevels of the interacting variables.\n\n## Exercises\n\n### 8E1\n\n(1) Bread dough rises because of yeast and temperature. Yeast amount and\ntemperature interact to determine how much the bread dough rises.\n(2) Education and parents' education could interact to determine higher\nincome. While people with more education have higher salaries on average,\npeople who are educated and also have educated parents are likely to have\neven higher average salaries at the same level of individual education.\n(3) Gasoline and pressing the accelerator make the car go. If you never press\nthe accelerator, a full tank won't do anything.\n\n### 8E2\n\nOnly statement one (Caramelizing onions requires cooking over a low heat and\nmaking sure the onions don't dry out) involves an interaction. Both things\nmust be true simultaneously, whereas the effects are independent of each\nother in the other statements.\n\n### 8E3\n\nOf course all of these models only make sense if we have a correct way to\nquantify those variables.\n\n(1) $\\text{onion caramelization} = \\alpha + \\beta_1 \\cdot \\text{temperature} + \\beta_2 \\cdot \\text{moisture} + \\gamma_{12} \\cdot \\text{temperature} \\cdot \\text{moisture}$\n(2) $\\text{car speed} = \\alpha + \\beta_2 \\cdot \\text{number of cylinders} + \\beta_2 \\cdot \\text{fuel injector quality}$\n(3) $\\text{political beliefs} = \\alpha + \\beta_1 \\cdot \\text{parental beliefs} + \\beta_2 \\cdot \\text{friend beliefs}$\n(4) $\\text{intelligence} = \\alpha + \\beta_1 \\cdot \\text{sociality} + \\beta_2 \\cdot \\text{manipulable appendages}.$\n\n### 8M1\n\nIn the tulips example, we saw that water and shade levels interact to affect\ntulip blooms. Tulips need both water and shade to produce blooms; at a low-light\nlevel, the effect of water decreases because no amount of water can replace\nthe lost light. Similarly, if plants have no water, an adequate amount of\nsunlight will not produce blooms and might even become harmful.\n\nIf the hot temperature prevents blooms all together, then the hot temperature\nwould modify the effect of shade, water, and their interaction to all become\nzero -- no amount of shade or water can allow for blooms, and their interaction\ndoes not help in this context either.\n\n### 8M2\n\nThe linear model for the tulips example without heat was\n$$\n\\mu_i = \\alpha + \\beta_W W_i + \\beta_S S_i + \\gamma_{SW} S_iW_i.\n$$\n\nWe can make all of those terms dependent on $H_i$, the heat treatment, in order\nto accomplish this.\n\n$$\n\\mu_i = \\alpha_{H[i]} + \\beta^{W}_{H[i]} + \\beta^S_{H[i]} + \\gamma^{SW}_{H[i]} S_iW_i.\n$$\n\nNow it is possible for these effects to all be zero (or much smaller)\nif $H[i] = 1$, and have\ntheir normal values if $H[i] = 0$. Another way to write this model could\nbe something like\n$$\n\\begin{aligned}\n\\mu_i &= \\lambda_i (1 - H_i) \\\\\n\\lambda_i &= \\alpha + \\beta_W W_i + \\beta_S S_i + \\gamma_{SW} S_iW_i\n\\end{aligned}\n$$\nwhere $H_i$ again takes on values of $0$ (cold) and $1$ (hot).\n\n### 8M3\n\nWe cannot create a data set where the raven population and wolf population\nhave a linear statistical interaction, because a linear statistical\ninteraction has at least two predictors. Here we only have an outcome\n(the raven population size) and a predictor (the wolf population size). This is\nmore of an example of a differential equations type problem than a statistical\ninteraction. In this model, the raven population size would have to vary\nwith the wolf population size, and we do not know about the functional\nform of this effect, so an appropriate model would be something like\n\n$$\n\\frac{dR}{dt} = f\\left(W(t)\\right),\n$$\nwhere $f$ is a function that takes the wolf population size at time $t$ as an\ninput, and returns the change in the raven population before the next\ntime point.\n\n### 8M4\n\nWe'll use the sample model for the tulip blooms without heat from the\n[earlier exercise](###8M2). The priors used in the chapter were\n\n$$\n\\begin{aligned}\n\\alpha &\\sim \\text{Normal}(0.5, 0.25) \\\\\n\\beta_W &\\sim \\text{Normal}(0, 0.25) \\\\\n\\beta_S &\\sim \\text{Normal}(0, 0.25) \\\\\n\\gamma_{SW} &\\sim \\text{Normal}(0, 0.25) \\\\\n\\end{aligned}\n$$\n\nWe want to use new priors that constrain the effect of water to be positive and\nthe effect of shade to be negative. At this point in the book, the\ndistribution we learned about that has to be positive is lognormal, and\nwe can force the effect of shade to be negative by taking the additive inverse\nof a lognormal prior. Since we know that having more water increases the effect\nof light (because if a tulip has plenty of water, getting enough sunshine is\nthe new limiting factor on the blooms), we know that having more water should\ndecrease the effect of shade, so we'll make the interaction negative as well.\nLognormal priors can be hard to calibrate, so we'll adjust the parameters\nuntil the prior predictive simulation looks nice. The priors we'll use are\nas follows.\n\n$$\n\\begin{aligned}\n\\mu_i &= \\alpha + \\beta_W W_i - \\beta_S S_i - \\gamma_{SW} S_iW_i \\\\\n\\alpha &\\sim \\text{Normal}(0.5, 0.25) \\\\\n\\beta_W &\\sim \\text{Log-normal}(-3, 1) \\\\\n\\beta_S &\\sim \\text{Log-normal}(-3, 1) \\\\\n\\gamma_{SW} &\\sim \\text{Log-normal}(-3, 1)\n\\end{aligned}\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(370)\n\n# Load the data\ndata(tulips)\nd <- tulips\nd$blooms_std <- d$blooms / max(d$blooms)\nd$water_cent <- d$water - mean(d$water)\nd$shade_cent <- d$shade - mean(d$shade)\n\n# Fit the model and extract the prior samples\nm_8m4 <- rethinking::quap(\n\talist(\n\t\tblooms_std ~ dnorm(mu, sigma),\n\t\tmu <- a + bw * water_cent - bs * shade_cent - bws * water_cent * shade_cent,\n\t\ta ~ dnorm(0.5, 0.25),\n\t\tbw  ~ dlnorm(-3, 1),\n\t\tbs  ~ dlnorm(-3, 1),\n\t\tbws ~ dlnorm(-3, 1),\n\t\tsigma ~ dexp(1)\n\t),\n\tdata = d\n)\n\nprior <- rethinking::extract.prior(m_8m4)\n\n# Plot the prpd\npar(mfrow = c(1, 3))\nfor (s in -1:1) {\n\tidx <- which(d$shade_cent == s)\n\tplot(\n\t\td$water_cent[idx],\n\t\td$blooms_std[idx],\n\t\txlim = c(-1, 1),\n\t\tylim = c(-0.5, 1.5),\n\t\txlab = \"water\",\n\t\tylab = \"blooms\",\n\t\tpch = 16,\n\t\tcol = rethinking::rangi2\n\t)\n\tabline(h = 0, lty = 2)\n\tabline(h = 1, lty = 2)\n\tmtext(paste0(\"shade = \", s))\n\tmu <- rethinking::link(\n\t\tm_8m4,\n\t\tdata = data.frame(shade_cent = s, water_cent = -1:1),\n\t\tpost = prior\n\t)\n\tfor (i in 1:20) lines(-1:1, mu[i, ], col = col.alpha(\"black\", 0.3))\n}\n```\n\n::: {.cell-output-display}\n![](cp8_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\nI did a few different simulations and ultimately ended up with the prior\nsimulation shown here. The slope priors are regularizing and skeptical,\nso we think that a smaller effect is more likely *a priori* -- if the effects\nare large, the data can demonstrate that for us.\n\n### 8H1\n\nNow we want to add the *bed* variable to the tulips example, which we'll\ndenote with $B_i$. We only want to include the bed effect as a main effect,\nwhich means we need to have a different intercept for each bed -- so our\nmodel will assume that each bed can start at a different baseline, but the\neffects of water, shade, and their interaction, are homogeneous across the\nbeds. This is probably an OK assumption in the context of a controlled\ngreenhouse setting.\n\nThe model will be as follows.\n\n$$\n\\begin{aligned}\ny_i &\\sim \\text{Normal} \\left(\\mu_i, \\sigma\\right) \\\\\n\\mu_i &= \\alpha_{B[i]} + \\beta_W W_i - \\beta_S S_i - \\gamma_{SW} S_iW_i \\\\\n\\alpha_{B[i]} &\\sim \\text{Normal}(0.5, 0.25) \\\\\n\\beta_W &\\sim \\text{Log-normal}(-3, 1) \\\\\n\\beta_S &\\sim \\text{Log-normal}(-3, 1) \\\\\n\\gamma_{SW} &\\sim \\text{Log-normal}(-3, 1) \\\\\n\\sigma &\\sim \\text{Exponential}(1)\n\\end{aligned}\n$$\n\nThat is, we'll use the same constrained, regularizing priors, as we did for the\nprevious problem, but we'll have a separate intercept for each bed. In reality,\nit would probably be good to have the intercept parameters be correlated as\nwell, but we haven't gone over that in the book yet. Let's go ahead and fit the\nmodel.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(370)\n# For the index coding to work, we need a numeric version of the beds.\nd$b <- as.integer(d$bed)\n\n# Fit the model\nm_8h1 <- rethinking::quap(\n\talist(\n\t\tblooms_std ~ dnorm(mu, sigma),\n\t\tmu <- a[b] + bw * water_cent - bs * shade_cent -\n\t\t\tbws * water_cent * shade_cent,\n\t\ta[b] ~ dnorm(0.5, 0.25),\n\t\tbw  ~ dlnorm(-3, 1),\n\t\tbs  ~ dlnorm(-3, 1),\n\t\tbws ~ dlnorm(-3, 1),\n\t\tsigma ~ dexp(1)\n\t),\n\tdata = d\n)\n\nrethinking::precis(m_8h1, depth = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           mean         sd       5.5%     94.5%\na[1]  0.2733479 0.03603110 0.21576327 0.3309326\na[2]  0.3964371 0.03601250 0.33888214 0.4539920\na[3]  0.4091452 0.03601137 0.35159204 0.4666983\nbw    0.2017188 0.02612291 0.15996936 0.2434683\nbs    0.1039759 0.02652450 0.06158467 0.1463672\nbws   0.1312346 0.03272451 0.07893448 0.1835347\nsigma 0.1091610 0.01511214 0.08500884 0.1333131\n```\n\n\n:::\n:::\n\n\n\nFrom the precis, we can see that the first bed (bed 1, with parameter `a[1]`)\nhas a lower intercept than the other two beds -- maybe this bed is next to\na drafty space, is the first bed in the water connection and gets the pipe\nsludge, or just had less bloomds for some reason. But after we account for\nthe different baselines between beds, the estimates of the parameter effects\nare similar to the last model, so this should just improve the accuracy of\nour model predictions for the first bed. We can plot the predictions to see.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the prpd\npar(mfrow = c(1, 3))\n\ncols <- c(\"#E69F00\", \"#56B4E9\", \"#009E73\")\n\nfor (s in -1:1) {\n\tidx <- which(d$shade_cent == s)\n\tplot(\n\t\td$water_cent[idx],\n\t\td$blooms_std[idx],\n\t\txlim = c(-1, 1),\n\t\tylim = c(-0.5, 1.5),\n\t\txlab = \"water\",\n\t\tylab = \"blooms\",\n\t\tpch = 16,\n\t\tcol = cols[d$b[idx]]\n\t)\n\tabline(h = 0, lty = 2)\n\tabline(h = 1, lty = 2)\n\tmtext(paste0(\"shade = \", s))\n\t\n\tfor (bd in 1:3) {\n\t\tmu <- rethinking::link(\n\t\t\tm_8h1,\n\t\t\tdata = data.frame(shade_cent = s, water_cent = -1:1, b = bd)\n\t\t)\n\t\tfor (i in 1:20) {\n\t\t\tlines(\n\t\t\t\t-1:1, mu[i, ],\n\t\t\t\tcol = col.alpha(cols[bd], 0.3)\n\t\t\t)\n\t\t}\n\t}\n}\n\nlegend(\"topright\", c(\"Bed a\", \"Bed b\", \"Bed c\"), col = cols, lty = 1)\n```\n\n::: {.cell-output-display}\n![](cp8_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nWhile it's actually quite difficult to make statistical conclusions without\nmultiple replicates (here we have only one measurement per bed per treatment),\nwe can see the clear difference between bed a and the other two beds in the\nmodel predictions. However, it also appears that our model predictions may\nnot capture the true effect, as from the observed data it seems plausible that\nthe effects of water and shade vary across beds. We would need actual\nreplicates to be more certain of that, though.\n\n### 8H2\n\nNow we can compare the models with and without bed using WAIC.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrethinking::compare(m_8m4, m_8h1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           WAIC        SE    dWAIC      dSE     pWAIC    weight\nm_8h1 -22.20890  9.935022 0.000000       NA 10.099017 0.7754177\nm_8m4 -19.73058 10.459586 2.478319 8.389834  7.390765 0.2245823\n```\n\n\n:::\n:::\n\n\n\nWe see that the WAIC is smaller for the model with bed included, although\nthe difference is small. This implies that adding the bed variable as a main\neffect increases the accuracy of our posterior predictions, although the\nimprovement is not spectacular. As we saw by looking at summaries of the\nposterior distribution in the previous exercise, the difference in the estimated\nintercept for bed A vs. bed b and bed c, without any major changes in the\nestimates of the slope parameters, should account for this difference.\n\n### 8H3\n\nFor this question, we'll focus on the `ruggedness` data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"rugged\")\n# Repeating data processing steps from the book\nd <- rugged\nd$log_gdp <- log(d$rgdppc_2000)\ndd <- d[complete.cases(d$rgdppc_2000), ]\ndd$log_gdp_std <- dd$log_gdp / mean(dd$log_gdp)\ndd$rugged_std <- dd$rugged / max(dd$rugged)\n\ndd$cid <- ifelse(dd$cont_africa == 1, 1, 2)\n```\n:::\n\n\n\nNow we need to recreate model `m8.5` from the chapter. Well, at least that's\nwhat the book says to do, but model `m8.5` is about the tulips example, so\nwe'll recreate `m8.3` instead.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm8.3 <- rethinking::quap(\n\talist(\n\t\tlog_gdp_std ~ dnorm(mu, sigma),\n\t\tmu <- a[cid] + b[cid] * (rugged_std - 0.215),\n\t\ta[cid] ~ dnorm(1, 0.1),\n\t\tb[cid] ~ dnorm(0, 0.3),\n\t\tsigma ~ dexp(1)\n\t),\n\tdata = dd\n)\nrethinking::precis(m8.3, depth = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            mean          sd        5.5%       94.5%\na[1]   0.8865629 0.015675157  0.86151094  0.91161480\na[2]   1.0505698 0.009936261  1.03468975  1.06644988\nb[1]   0.1325055 0.074201996  0.01391637  0.25109461\nb[2]  -0.1425764 0.054747543 -0.23007353 -0.05507924\nsigma  0.1094903 0.005934777  0.10000535  0.11897519\n```\n\n\n:::\n:::\n\n\n\nWe got similar results to what's in the book, which is good. Now we want to\nexamine the model with PSIS to determine if the Seychelles are influential\non the estimation of parameters for the Africa group.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(370)\nm8.3_psis <- rethinking::PSIS(m8.3, pointwise = TRUE, n = 20000)\nrownames(m8.3_psis) <- dd$isocode\npsis_sort <- m8.3_psis[order(m8.3_psis$k, decreasing = TRUE), ]\npsis_sort |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          PSIS       lppd    penalty  std_err         k\nLSO -1.1417140  0.5708570 0.31929940 15.27576 0.4467221\nSYC  1.3274852 -0.6637426 0.63043059 15.27576 0.3947676\nCHE  2.8274338 -1.4137169 0.46756727 15.27576 0.3148571\nTJK  0.4998540 -0.2499270 0.30731105 15.27576 0.2365403\nGNQ  3.3713051 -1.6856526 0.21035122 15.27576 0.2249513\nMUS  0.8394823 -0.4197411 0.08626176 15.27576 0.1688589\n```\n\n\n:::\n:::\n\n\n\nThe most influential country on the model fit, judging by the Pareto $k$ values,\nare Lesotho and the Seychelles, which are both highly rugged nations in Africa.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\ndd_sorted <- dd[order(m8.3_psis$k, decreasing = TRUE), ]\nplot(\n\tdd_sorted$rugged_std, psis_sort$k,\n\txlab = \"Ruggedness as prop. of maximum\",\n\tylab = \"PSIS Pareto k value\"\n)\n```\n\n::: {.cell-output-display}\n![](cp8_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\nWe can see that highly rugged nations have the largest Pareto $k$ values,\nindicating that they are the most influential variables. We also know that\nthese values have a high leverage in a linear regression model, so that makes\nsense.\n\nNow that we know these nations with high ruggedness are having an oversized\neffect on the estimated trend, we can try to use robust regression to\nlower their influence. We'll use the same model, but with a Student's $t$\ndistribution likelihood (with 2 d.f.) instead of a Normal likelihood. Personally\nI prefer 3 degrees of freedom (the variance of the distribution is infinite if\nthe d.f. is not larger than 2, which is a prior belief that never makes sense\nin a physical context to me), but for now I'll do what the textbook says.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm8.3_r <- rethinking::quap(\n\talist(\n\t\tlog_gdp_std ~ dstudent(nu = 2, mu, sigma),\n\t\tmu <- a[cid] + b[cid] * (rugged_std - 0.215),\n\t\ta[cid] ~ dnorm(1, 0.1),\n\t\tb[cid] ~ dnorm(0, 0.3),\n\t\tsigma ~ dexp(1)\n\t),\n\tdata = dd\n)\nrethinking::precis(m8.3_r, depth = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             mean         sd        5.5%       94.5%\na[1]   0.86259888 0.01614146  0.83680170  0.88839606\na[2]   1.04577255 0.01097134  1.02823823  1.06330688\nb[1]   0.11241664 0.07503557 -0.00750470  0.23233797\nb[2]  -0.21378054 0.06352620 -0.31530767 -0.11225341\nsigma  0.08451473 0.00673094  0.07375738  0.09527207\n```\n\n\n:::\n:::\n\n\n\nWe can see by comparing the two model summaries that a few of the\nparameters are slightly different. Let's now compare the models using PSIS.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12312)\nrethinking::compare(m8.3, m8.3_r, func = PSIS, n = 20000)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            PSIS       SE    dPSIS      dSE    pPSIS       weight\nm8.3   -258.8088 15.27974  0.00000       NA 5.318484 1.000000e+00\nm8.3_r -221.8080 18.11559 37.00089 5.884289 5.760308 9.233328e-09\n```\n\n\n:::\n:::\n\n\n\nHere, we can see that the non-robust model actually appears to be giving us\nworse predictions than the non-robust model. However, we know that PSIS is\njust a measure of predictive performance, so it's possible that our\nrobust model is still a better conceptual model that provides more accurate\ninferences at the cost of appearing to underfit the data. Since the\ntwo models have every similar numbers of parameters, predictive accuracy\ncriteria are likely to be more sensitive to this kind of \"underfitting\", when\nwe actually know outside of the statistics world that we're reducing the\nimpact of outlying values.\n\nAnyways, we can also look at the individual pareto $k$ values for the new\nmodel.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(370)\nm8.3r_psis <- rethinking::PSIS(m8.3_r, pointwise = TRUE, n = 20000)\nrownames(m8.3r_psis) <- dd$isocode\npsis_sort_r <- m8.3r_psis[order(m8.3r_psis$k, decreasing = TRUE), ]\npsis_sort_r |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         PSIS      lppd     penalty std_err          k\nEST -2.787885 1.3939424 0.007899841 18.1216 0.13309736\nLSO -1.553968 0.7769838 0.264018936 18.1216 0.11825246\nALB -2.720143 1.3600717 0.013599882 18.1216 0.11215073\nATG -2.777583 1.3887917 0.008395917 18.1216 0.10169758\nUGA -2.744650 1.3723251 0.010101504 18.1216 0.09032803\nBEN -2.552244 1.2761221 0.019180005 18.1216 0.08104976\n```\n\n\n:::\n:::\n\n\n\nNow we can see that the pareto $k$ values are all much lower. While Lesotho\nstill appears in the top 6, it is overall much less influential, and Seychelles\nno longer appears in the top 6.\n\n### 8H4\n\nFor this problem, we'll use the `nettle` data to examine the hypothesis\nthat higher food security leads to a higher language diversity in a region.\n\nFirst we need to construct the outcome variable.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(nettle)\nd <- nettle\nd$lang.per.cap <- d$num.lang / d$k.pop\n\n# The log of this will be our actual outcome variable\nd$log.lang.per.cap <- log10(d$lang.per.cap)\n\n# Center the outcome\nybar <- mean(d$log.lang.per.cap)\nd$std.log.lang.per.cap <- d$log.lang.per.cap - ybar\n\n# We also need the log of the area\nd$log.area <- log10(d$area)\n```\n:::\n\n\n\nSince I don't really know anything about this problem other than what the\ntextbook tells me, I'll follow the specified steps. The effects we want to\nevaluate here are the effects of `mean.growing.season`, which we'll call $M$,\nand `sd.growing.season`, on our model. We also need to consider $A$, the log of\n`area`, as a potential cause. I'm not sure how we would work in the number of\nweather stations in our model, so for now we'll leave that alone -- although\nthere is a noticeable trend in the data that as the number of measurement\nstations increased, so did the SD of the growing season length. So in a real\nacademic paper, we would definitely need to think about how to model that.\n\nFirst let's look at the bivariate relationship between each of these values and\nthe outcome.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlayout(matrix(c(1, 2, 3), nrow = 1))\nplot(\n\td$mean.growing.season, d$log.lang.per.cap,\n\txlab = \"Mean length of growing season (months)\",\n\tylab = \"log10 number of langauges per capita\"\n)\nplot(\n\td$sd.growing.season, d$log.lang.per.cap,\n\txlab = \"Standard deviation of length of growing season (months)\",\n\tylab = \"\"\n)\nplot(\n\td$log.area, d$log.lang.per.cap,\n\txlab = \"log10 area of country (sq. km.)\",\n\tylab = \"\"\n)\n```\n\n::: {.cell-output-display}\n![](cp8_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\nIn general, none of these trends looks particularly strong, although\nthere appear to be some trends with the growing season variables.\n\nNow, let's try to fit a simple model that models the log languages per\ncapita based on the mean length of the growing season. We'll use a normal\nlikelihood since the outcome variable is on the log scale. Since we aren't\nusing a count model, which would naturally constrict the domain of the\noutcome variable, I also chose to center the outcome variable before\nmodeling to make assigning a prior for the intercept feasible.\n\nFor the intercept, we'll use a generic prior centered at 0 (the mean after\nstandardization). For the effect of the mean growing season length, we'll\nuse a regularizing, skeptical prior centered around 0.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set seed for all of our models in this section\nset.seed(370)\nm_mgs <- rethinking::quap(\n\tflist = alist(\n\t\tstd.log.lang.per.cap ~ dnorm(mu, sigma),\n\t\tmu <- a + b_mgsl * mean.growing.season,\n\t\ta ~ dnorm(0, 5),\n\t\tb_mgsl ~ dnorm(0, 1),\n\t\tsigma ~ dexp(1)\n\t),\n\tdata = d\n)\nrethinking::precis(m_mgs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             mean         sd        5.5%      94.5%\na      -0.5310682 0.17466211 -0.81021195 -0.2519244\nb_mgsl  0.0754357 0.02267654  0.03919421  0.1116772\nsigma   0.6095826 0.04980052  0.52999173  0.6891734\n```\n\n\n:::\n:::\n\n\n\nWe can see from the summary that there is a small prior effect of mean\ngrowing season length on the outcome. Now, let's check whether the\narea should be a coefficient in this model as well.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_mgs_a <- rethinking::quap(\n\tflist = alist(\n\t\tstd.log.lang.per.cap ~ dnorm(mu, sigma),\n\t\tmu <- a + b_mgsl * mean.growing.season + b_area * log.area,\n\t\ta ~ dnorm(0, 5),\n\t\tb_mgsl ~ dnorm(0, 1),\n\t\tb_area ~ dnorm(0, 1),\n\t\tsigma ~ dexp(1)\n\t),\n\tdata = d\n)\nrethinking::precis(m_mgs_a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             mean         sd        5.5%      94.5%\na       0.6533186 0.83024907 -0.67357977 1.98021696\nb_mgsl  0.0629484 0.02394189  0.02468463 0.10121217\nb_area -0.1952263 0.13386781 -0.40917288 0.01872034\nsigma   0.6009410 0.04909953  0.52247048 0.67941155\n```\n\n\n:::\n:::\n\n\n\nThe effect of the area variable is negative and a large amount of the\ndensity lies below zero, which suggests that the area could be a real effect that\nwe need to control for. Controlling for the area size also affects out estimate\nof the effect of mean growing season length. Let's compare the models via WAIC\nand see if the area improves posterior predictions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrethinking::compare(m_mgs, m_mgs_a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            WAIC       SE     dWAIC      dSE    pWAIC   weight\nm_mgs   144.5949 15.49001 0.0000000       NA 3.778308 0.539875\nm_mgs_a 144.9146 16.01579 0.3196787 3.673048 5.049032 0.460125\n```\n\n\n:::\n:::\n\n\n\nThe WAICs are extremely similar, and the WAIC for the model without area\nis slightly better, so I don't think we need area in this model. If we think\nabout the problem casually, I don't understand why the area would be a\nconfounder or a collider in this situation, because the area doesn't\ncasually determine the mean growing season length in a country. However, larger\ncountries should have more variation in the growing season length (since larger\narea overall means they can cover more areas of varying latitude).\nBut, I think that a larger area should mean there is more room for multiple\ncommunities to exist and become isolated, so a larger country should also have\nmore languages on average.\n\nSo I think the DAG should look something like this.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlayout(c(1))\ndag <- dagitty::dagitty(\n\t'DAG {\n\t\"languages\" <- \"mean length\"\n\t\"languages\" <- \"SD length\" <- \"area\"\n\t\"languages\" <- \"area\"\n\t}'\n)\ncoordinates(dag) <- list(\n\tx = c(\"languages\" = 0, \"mean length\" = 1, \"SD length\" = -1, \"area\" = -1),\n\ty = c(\"languages\" = 0, \"mean length\" = 0, \"SD length\" = 0.5, \"area\" = -0.5)\n)\nplot(dag)\n```\n\n::: {.cell-output-display}\n![](cp8_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\nSo, in our final model we'll need to include area anyways, so we might as\nwell leave it in there for now.\n\nNext we want to examine the effect of the SD of growing season length on\nlanguages. The `area` variable is a confounder in this casual structure, so\nwe need to include that as well to avoid getting a biased estimate.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_sgs_a <- rethinking::quap(\n\tflist = alist(\n\t\tstd.log.lang.per.cap ~ dnorm(mu, sigma),\n\t\tmu <- a + b_sgsl * sd.growing.season + b_area * log.area,\n\t\ta ~ dnorm(0, 5),\n\t\tb_sgsl ~ dnorm(0, 1),\n\t\tb_area ~ dnorm(0, 1),\n\t\tsigma ~ dexp(1)\n\t),\n\tdata = d\n)\nrethinking::precis(m_sgs_a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              mean         sd       5.5%      94.5%\na       1.43691137 0.79286148  0.1697656 2.70405716\nb_sgsl -0.09330776 0.07997807 -0.2211282 0.03451264\nb_area -0.22761855 0.15173599 -0.4701220 0.01488487\nsigma   0.62213062 0.05082317  0.5409054 0.70335587\n```\n\n\n:::\n:::\n\n\n\nWe see that the SD of growing season length does appear to have a negative\neffective on the overall number of languages. We cannot rule out entirely\nthe lack of an effect (assuming our causal structure is correct and\nlinear models are appropriate), but there is likely to be a negative\neffect of the SD of growing length on number of languages.\n\nSo far we've seen that an average longer growing season leads to more languages\nper capita, meaning that more food abundance leads to smaller, more isolated\nsocial groups and the development of more languages. However, higher variation\nin the growing season length leads to lower languages per capita, suggesting\nthe need to form larger social networks for insurance against short growing\nseasons. In both models, we saw a negative effect of area, indicating that\nas a country becomes larger, the number of languages becomes smaller, which\nis the opposite of what I would have thought. Perhaps larger countries, on\naverage, have shorter growing seasons? We can examine that effect quickly.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlayout(matrix(c(1, 2), nrow = 1))\nplot(\n\td$mean.growing.season, d$log.area,\n\txlab = \"Mean length of growing season (months)\",\n\tylab = \"log10 area of country (sq. km.)\"\n)\nplot(\n\td$sd.growing.season, d$log.area,\n\txlab = \"Standard deviation of length of growing season (months)\",\n\tylab = \"\"\n)\n```\n\n::: {.cell-output-display}\n![](cp8_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\nInterestingly, we can see slight patterns in both trends. Larger countries\nseem to have slightly smaller average growing seasons, and more uncertainty\nin their growing seasons. I think the effect on the mean length of the\ngrowing season is quite small, and is likely to not be causal, although we\ncould postulate that larger countries tend to cover more sparsely inhabited\nterritory which has a shorter growing season. There is a definite trend in the\nstandard deviation of the growing season though -- it's hard to tell if this\nis an effect of covering more latitude areas, or a function of a number of\nmeasuring systems. We would need a variable on the range of latitude covered\nby each country to disentangle those effects.\n\nAnyways, now we can fit the main model. We'll fit two models that include all\nthree variables. One will include just main effects, and the other will include\nan interaction between the effects of mean and SD of growing season length.\nThen we can compare those models.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_noint <- rethinking::quap(\n\tflist = alist(\n\t\tstd.log.lang.per.cap ~ dnorm(mu, sigma),\n\t\tmu <- a + b_sgsl * sd.growing.season + b_mgsl * mean.growing.season +\n\t\t\tb_area * log.area,\n\t\ta ~ dnorm(0, 5),\n\t\tb_mgsl ~ dnorm(0, 1),\n\t\tb_sgsl ~ dnorm(0, 1),\n\t\tb_area ~ dnorm(0, 1),\n\t\tsigma ~ dexp(1)\n\t),\n\tdata = d\n)\n\nrethinking::precis(m_noint)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              mean         sd        5.5%       94.5%\na      -0.19725369 0.91289412 -1.65623482  1.26172743\nb_mgsl  0.07583973 0.02418582  0.03718613  0.11449334\nb_sgsl -0.15778988 0.07809425 -0.28259957 -0.03298018\nb_area -0.01221519 0.15896098 -0.26626554  0.24183516\nsigma   0.58530486 0.04782868  0.50886538  0.66174433\n```\n\n\n:::\n:::\n\n\n\nAfter including both the mean and SD of growing season length in the\nmodel, the effect of area goes away. This suggests that the effect of area on\nthe number of languages per capita is completely explained by the\neffect of the growing season -- we have no evidence here for a direct causal\neffect of area, meaning that more room for expansion doesn't say anything about\nthe number of languages we expect to see, unless we know how habitable the\nland is first. In this model, we see a positive effect of the mean and\nnegative effect of the SD as we expect. Now we can look at a possible\ninteraction.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_int <- rethinking::quap(\n\tflist = alist(\n\t\tstd.log.lang.per.cap ~ dnorm(mu, sigma),\n\t\tmu <- a + b_sgsl * sd.growing.season + b_mgsl * mean.growing.season +\n\t\t\tb_intr * mean.growing.season * sd.growing.season + b_area * log.area,\n\t\ta ~ dnorm(0, 5),\n\t\tb_mgsl ~ dnorm(0, 1),\n\t\tb_sgsl ~ dnorm(0, 1),\n\t\tb_intr ~ dnorm(0, 1),\n\t\tb_area ~ dnorm(0, 1),\n\t\tsigma ~ dexp(1)\n\t),\n\tdata = d\n)\n\nrethinking::precis(m_int)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               mean         sd        5.5%       94.5%\na      -0.607666693 0.90104859 -2.04771636  0.83238298\nb_mgsl  0.128691044 0.03267891  0.07646384  0.18091825\nb_sgsl  0.179426213 0.16417241 -0.08295301  0.44180543\nb_intr -0.046560229 0.02012491 -0.07872372 -0.01439674\nb_area -0.007638564 0.15385114 -0.25352240  0.23824527\nsigma   0.565320615 0.04620557  0.49147519  0.63916604\n```\n\n\n:::\n:::\n\n\n\nIt certainly looks like the results are different, which is qualitatively\nimportant to understand. But let's first check the WAIC to get an idea of\nhow much better our interaction model is doing.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrethinking::compare(m_noint, m_int)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            WAIC       SE    dWAIC      dSE    pWAIC    weight\nm_int   139.8943 16.19209 0.000000       NA 6.821918 0.8329129\nm_noint 143.1071 16.09151 3.212828 4.717323 6.073994 0.1670871\n```\n\n\n:::\n:::\n\n\n\nOK, it's only a bit better in terms of predictive accuracy, but the estimates\nare so different that we need to try and understand what's going on here.\n\nWhen we include an interaction term, the effect of the standard deviation on its\nown largely goes away, and the effect of the negative is negative with almost\nall of the probability mass below 0. This suggests that by itself, the SD\nis not important for determining the number of languages -- we need to know\nthe mean first. I think we need to make a plot to really understand this\neffect.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the prpd\nlayout(matrix(c(1, 2, 3, 4), nrow = 2, byrow = TRUE))\n\nsd_vals <- c(0, 1.5, 3, 4.5)\nsample_n <- 500\nncolors <- 10\ncols <- viridisLite::plasma(ncolors)\nrank <- as.factor(as.numeric(cut(d$sd.growing.season, ncolors)))\n\nfor (i in 1:length(sd_vals)) {\n\tsd <- sd_vals[i]\n\tidx <- which(dplyr::between(d$sd.growing.season, sd - 1.5, sd + 1.5))\n\tplot(\n\t\t#d$mean.growing.season[idx],\n\t\t#d$log.lang.per.cap[idx],\n\t\tNULL, NULL,\n\t\txlim = c(0, 12),\n\t\tylim = 10 ^ c(-4, 0),\n\t\txaxs = \"i\",\n\t\tyaxs = \"i\",\n\t\txlab = \"Mean growing season length (months)\",\n\t\tylab = \"Number of languages per capita\",\n\t\tpch = 16,\n\t\tlog = \"y\"\n\t\t#col = cols[rank[idx]]\n\t)\n\tmtext(paste0(\"SD of growing season = \", sd))\n\t\n\t# Calculate the posterior values\n\tpost_data <- expand.grid(\n\t\tmean.growing.season = seq(0, 12, 0.1),\n\t\tsd.growing.season = sd,\n\t\tlog.area = mean(d$log.area)\n\t)\n\t\n\tmu <- rethinking::link(m_int, post_data, n = sample_n)\n\t\n\tfor (i in 1:sample_n) {\n\t\tlines(\n\t\t\tseq(0, 12, 0.1), 10 ^ (mu[i, ] + ybar),\n\t\t\tcol = col.alpha(\"black\", 0.1)\n\t\t)\n\t}\n}\n```\n\n::: {.cell-output-display}\n![](cp8_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\nFrom the posterior predictions, we can understand the effect of the interaction\na lot easier. The posterior predictions shown all use the average value of the\nlog land area, but the main thing we want to understand here is the qualitative\nway the effect changes. When the SD value is small (the points shown in the\ntop right panel are from 0 to 1.5), there is little variation in the length\nof the growing season, and the effect of the average length of the growing\nseason on language diversity is positive. However, as the variation in\ngrowing season length increases, the effect becomes smaller and then negative,\nindicating that for highly variable areas, there is little effect of the\naverage growing season on language diversity. For extremely variable areas,\na long growing season may even lead to less language diversity, but we do\nnot have enough data to say that conclusively.\n\n\n### 8H5\n\nFor this exercise, we'll build a model using the `Wines2012` dataset.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"Wines2012\")\nd <- Wines2012\n```\n:::\n\n\n\nIt looks like the wines are scores out of 20, so normally I would recommend\na binomial (or beta-binomial) model here. But we don't know that for sure\nand we haven't learned that yet, so we'll standardize the scores and\nmodel the $z$-scores instead. This is a fairly interesting problem even\nwith the small amount of data we have, and I imagine will make quite an\ninteresting multilevel modeling problem later in the book.\n\nFor this question, we just need to include effects of the judge and of the\nwine.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndd <- data.frame(\n\ty = rethinking::standardize(d$score),\n\tj = rethinking::coerce_index(d$judge),\n\tw = rethinking::coerce_index(d$wine),\n\twine_amer = d$wine.amer,\n\tjudge_amer = d$judge.amer,\n\tred = as.integer(ifelse(d$flight == \"red\", 1, 0))\n)\ndplyr::glimpse(dd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 180\nColumns: 6\n$ y          <dbl> -1.57660412, -0.45045832, -0.07507639, 0.30030555, -2.32736…\n$ j          <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,…\n$ w          <int> 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 1, 3, 5, 7, 9, 11, 13, 1…\n$ wine_amer  <int> 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,…\n$ judge_amer <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ red        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n```\n\n\n:::\n:::\n\n\n\nFirst we can try to visualize the data. It's a bit difficult because we have\ntwo categorical variables and one continuous (perfect two-way anova design),\nbut we can make two plots to try and see what's going on.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd$j2 <- rethinking::coerce_index(d$judge) |> factor()\np1 <-\n\tggplot(d) +\n\taes(x = wine, y = score) +\n\tgeom_point() +\n\tfacet_wrap(~j2) +\n\thgp::theme_ms() +\n\ttheme(axis.text = element_text(size = 8, angle = 90))\n\np2 <-\n\tggplot(d) +\n\taes(x = j2, y = score) +\n\tgeom_point() +\n\tfacet_wrap(~wine) +\n\thgp::theme_ms() +\n\ttheme(axis.text = element_text(size = 10)) + labs(x = \"judge\")\n\ncowplot::plot_grid(p1, p2, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](cp8_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n\nOf course with data like these we just kind of have to eyeball them and make\nqualitative guesses as to what might be going on. But In general we can\nsee there are some nicer judges (5, 3), and some meaner judges (4, 9), and\none judge that got meaner as they tried more wines (8). However, most of the\nwines look fairly similar with the exception of a few like C2 and I2 that\nappeared to get worse bad reviews. I guess if we were following Agresti's\n*Categorical Data Analysis* the next thing to do would be to get marginal\nand conditional mean scores, but we don't need to do that now, we can\nstart fitting models (which does that in an easier way, more or less).\n\nWe'll use (as usual) a normal likelihood -- a $t$-likelihood might be better\nif some of our judges or wines give outlying scores, but for now we'll\nignore that possibility. Next we need to assign priors. Fortunately for\nus this is easy and I'll just assign a typical normal prior, I'm not too\nsure why it really needs to be justified. So let's go ahead and fit the\nfirst model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12312)\nm_w1 <- rethinking::quap(\n\tflist = alist(\n\t\ty ~ dnorm(mu, sigma),\n\t\tmu <- a_w[w] + a_j[j],\n\t\ta_w[w] ~ dnorm(0, 2),\n\t\ta_j[j] ~ dnorm(0, 2),\n\t\tsigma ~ dexp(1)\n\t),\n\tdata = dd\n)\n\nlayout(matrix(c(1, 2), nrow = 1))\nrethinking::precis(m_w1, depth = 2, pars = paste0(\"a_w[\", 1:20, \"]\")) |>\n\tprecis_plot()\nmtext(\"Wine parameters\")\nrethinking::precis(m_w1, depth = 2, pars = paste0(\"a_j[\", 1:9, \"]\")) |>\n\tprecis_plot()\nmtext(\"Judge parameters\")\n```\n\n::: {.cell-output-display}\n![](cp8_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\nLike we thought from looking at the plots, the judges appear to be more\ndifferent from each other than the wines are. We probably also want to know\nabout how the judges and wines interact, but since we don't have any replicates,\nwe can't really get good answers for that question, all we can do is look\nat the score in each cell.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d) +\n\taes(x = wine, y = judge, fill = score) +\n\tgeom_tile() +\n\tscale_fill_viridis_c(breaks = c(7, 10, 15, 19), limits = c(7, 19.5)) +\n\thgp::theme_ms() +\n\tguides(fill = guide_colorbar(barwidth = 15))\n```\n\n::: {.cell-output-display}\n![](cp8_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n\n### 8H6\n\nNow instead of looking at the variability across judges and across wines, we\nwant to try and use the characteristics of the judges and wines to understand\nthe scores. For this problem, we won't include any interactions. Again,\nwe'll use standard priors, and the variables we'll include as main effects are\n`flight` (whether the wine is red or white), `wine.amer` (if the wine was\nmade in America), and `judge.amer` (whether the judge is American).\n\nFor whatever reason, the book says to use indicator coding for this problem and\nthe next problem (coding interactions between two categorical variables\nis annoying somehow, I tried it and couldn't figure it out). So we'll do that.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_w2 <-\n\trethinking::quap(\n\t\tflist = alist(\n\t\t\ty ~ dnorm(mu, sigma),\n\t\t\tmu <- a + a_wa * wine_amer + a_ja * judge_amer + a_red * red,\n\t\t\ta ~ dnorm(0, 2),\n\t\t\ta_wa ~ dnorm(0, 2),\n\t\t\ta_ja ~ dnorm(0, 2),\n\t\t\ta_red ~ dnorm(0, 2),\n\t\t\tsigma ~ dexp(1)\n\t\t),\n\t\tdata = dd\n\t)\n\nrethinking::precis(m_w2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              mean         sd        5.5%      94.5%\na     -0.020886459 0.15873255 -0.27457173 0.23279881\na_wa  -0.191038758 0.14889489 -0.42900156 0.04692404\na_ja   0.247752111 0.14683135  0.01308725 0.48241697\na_red -0.004204578 0.14595115 -0.23746271 0.22905355\nsigma  0.982341917 0.05156316  0.89993403 1.06474980\n```\n\n\n:::\n:::\n\n\n\nOverall, the red and white wines were judged similarly without a large discrepancy\nbetween groups. American judges tended to be more generous, and American wines\ntended to be rated slightly worse. However, we have a great deal of uncertainty\nabout all of these parameters.\n\n### 8H7\n\nApparently doing the interactions IS the reason for using indicator coding\nhere, quap I guess can't handle all the stuff that Stan can. Now we want\nto include all of the third-level interactions that we can make.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_w3 <-\n\trethinking::quap(\n\t\tflist = alist(\n\t\t\ty ~ dnorm(mu, sigma),\n\t\t\tmu <- a + a_wa * wine_amer + a_ja * judge_amer + a_red * red +\n\t\t\t\t# American wine/american judge\n\t\t\t\tg_wawj * wine_amer * judge_amer +\n\t\t\t\t# American red wines\n\t\t\t\tg_rwa * wine_amer * red +\n\t\t\t\t# Red wines / american judge\n\t\t\t\tg_rja * judge_amer * red,\n\t\t\ta ~ dnorm(0, 2),\n\t\t\ta_wa ~ dnorm(0, 2),\n\t\t\ta_ja ~ dnorm(0, 2),\n\t\t\ta_red ~ dnorm(0, 2),\n\t\t\tg_wawj ~ dnorm(0, 2),\n\t\t\tg_rwa ~ dnorm(0, 2),\n\t\t\tg_rja ~ dnorm(0, 2),\n\t\t\tsigma ~ dexp(1)\n\t\t),\n\t\tdata = dd\n\t)\n\nrethinking::precis(m_w3, depth = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              mean         sd       5.5%      94.5%\na      -0.21373267 0.21651035 -0.5597580  0.1322927\na_wa    0.15272583 0.26069131 -0.2639092  0.5693609\na_ja    0.29244412 0.26673524 -0.1338503  0.7187386\na_red   0.31208633 0.27442703 -0.1265011  0.7506737\ng_wawj -0.11070543 0.29175737 -0.5769901  0.3555792\ng_rwa  -0.56956098 0.29026516 -1.0334608 -0.1056612\ng_rja   0.04190135 0.28649695 -0.4159761  0.4997788\nsigma   0.97130887 0.05098788  0.8898204  1.0527973\n```\n\n\n:::\n:::\n\n\n\nUsually I hate looking at tables, but this one is not too bad because the\ntrend is pretty obvious. All of the parameters are zero-ish (lots of\nprobably mass on either side of 0), except for one, which is `g_rwa`. This is\nthe interaction term between American wines and red wines -- so it looks like\nAmerican red wines were much worse on average than non-american and/or non-red\nwines.\n\nIn the solutions guide, Richard actually gives a good reason for using more\nskeptical priors for the interaction terms than on the main effect terms.\nI need to remember that for the future.\n\n<!-- END OF FILE -->\n",
    "supporting": [
      "cp8_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}